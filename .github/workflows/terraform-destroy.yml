name: Terraform Destroy Enhanced

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type "destroy" to confirm'
        required: true
        default: ''
      target:
        description: 'Destroy target'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - app-only
        - infrastructure-only
      cleanup_backend:
        description: 'Also delete S3 bucket and DynamoDB table? (yes/no)'
        required: false
        default: 'no'

env:
  TF_VERSION: '1.5.0'
  AWS_REGION: eu-north-1
  EKS_CLUSTER_NAME: retail-store
  TF_STATE_BUCKET: tfstate-509d3870-eu-north-1
  TF_STATE_KEY: eks/minimal/terraform.tfstate
  TF_STATE_LOCK_TABLE: retail-store-terraform-locks

jobs:
  destroy-application:
    name: Destroy Application
    runs-on: ubuntu-latest
    if: github.event.inputs.confirm == 'destroy' && (github.event.inputs.target == 'all' || github.event.inputs.target == 'app-only')
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER_NAME }}

    - name: Delete Application and Dependencies
      run: |
        echo "Deleting application resources..."
        kubectl delete -f https://github.com/aws-containers/retail-store-sample-app/releases/latest/download/kubernetes.yaml --ignore-not-found=true
        
        echo "Deleting leftover LoadBalancers..."
        kubectl get svc --all-namespaces -o json | jq -r '.items[] | select(.spec.type=="LoadBalancer") | .metadata.name' | while read svc; do
          kubectl delete svc $svc --ignore-not-found=true
        done
        
        echo "Cleaning up AWS ELBs..."
        aws elbv2 describe-load-balancers --region ${{ env.AWS_REGION }} --query 'LoadBalancers[?contains(LoadBalancerName, `k8s-`)].LoadBalancerArn' --output text | while read lb_arn; do
          if [ -n "$lb_arn" ]; then
            echo "Deleting LoadBalancer: $lb_arn"
            aws elbv2 delete-load-balancer --load-balancer-arn $lb_arn --region ${{ env.AWS_REGION }} || true
          fi
        done

  terraform-destroy:
    name: Terraform Destroy Infrastructure
    runs-on: ubuntu-latest
    needs: destroy-application
    if: always() && github.event.inputs.confirm == 'destroy' && (github.event.inputs.target == 'all' || github.event.inputs.target == 'infrastructure-only')
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TF_VERSION }}

    - name: Terraform Init with Backend
      run: terraform init \
              -backend-config="bucket=${{ env.TF_STATE_BUCKET }}" \
              -backend-config="key=${{ env.TF_STATE_KEY }}" \
              -backend-config="region=${{ env.AWS_REGION }}" \
              -backend-config="dynamodb_table=${{ env.TF_STATE_LOCK_TABLE }}"
      working-directory: terraform/eks/minimal

    - name: Terraform Destroy with Enhanced Cleanup
      run: |
        set -e
        echo "Running terraform destroy..."
        terraform destroy -auto-approve || {
          echo "First destroy attempt failed, performing cleanup..."
          VPC_ID=$(terraform output -raw vpc_id 2>/dev/null || echo "")
          
          if [ -n "$VPC_ID" ]; then
            echo "Cleaning resources in VPC: $VPC_ID"
            
            # Delete VPC Endpoints
            while read endpoint_id; do
              [ -n "$endpoint_id" ] && aws ec2 delete-vpc-endpoint --vpc-endpoint-id $endpoint_id --region ${{ env.AWS_REGION }} || true
            done < <(aws ec2 describe-vpc-endpoints --region ${{ env.AWS_REGION }} --filters "Name=vpc-id,Values=$VPC_ID" --query 'VpcEndpoints[].VpcEndpointId' --output text | tr '\t' '\n')
            
            # Delete NAT Gateways
            while read nat_id; do
              [ -n "$nat_id" ] && aws ec2 delete-nat-gateway --nat-gateway-id $nat_id --region ${{ env.AWS_REGION }} || true
            done < <(aws ec2 describe-nat-gateways --region ${{ env.AWS_REGION }} --filter "Name=vpc-id,Values=$VPC_ID" --query 'NatGateways[?State!=`deleted`].NatGatewayId' --output text | tr '\t' '\n')
            
            # Delete ENIs
            while read eni_id; do
              [ -n "$eni_id" ] && aws ec2 delete-network-interface --network-interface-id $eni_id --region ${{ env.AWS_REGION }} || true
            done < <(aws ec2 describe-network-interfaces --region ${{ env.AWS_REGION }} --filters "Name=vpc-id,Values=$VPC_ID" --query 'NetworkInterfaces[?Status!=`in-use`].NetworkInterfaceId' --output text | tr '\t' '\n')
            
            # Delete Security Groups (non-default)
            while read sg_id; do
              [ -n "$sg_id" ] && aws ec2 delete-security-group --group-id $sg_id --region ${{ env.AWS_REGION }} || true
            done < <(aws ec2 describe-security-groups --region ${{ env.AWS_REGION }} --filters "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[?GroupName!=`default`].GroupId' --output text | tr '\t' '\n')
            
            # Delete Route Tables (non-main)
            while read rt_id; do
              [ -n "$rt_id" ] && aws ec2 delete-route-table --route-table-id $rt_id --region ${{ env.AWS_REGION }} || true
            done < <(aws ec2 describe-route-tables --region ${{ env.AWS_REGION }} --filters "Name=vpc-id,Values=$VPC_ID" --query 'RouteTables[?Associations[0].Main!=`true`].RouteTableId' --output text | tr '\t' '\n')
            
            # Detach & Delete IGWs
            while read igw_id; do
              if [ -n "$igw_id" ]; then
                aws ec2 detach-internet-gateway --internet-gateway-id $igw_id --vpc-id $VPC_ID --region ${{ env.AWS_REGION }} || true
                aws ec2 delete-internet-gateway --internet-gateway-id $igw_id --region ${{ env.AWS_REGION }} || true
              fi
            done < <(aws ec2 describe-internet-gateways --region ${{ env.AWS_REGION }} --filters "Name=attachment.vpc-id,Values=$VPC_ID" --query 'InternetGateways[].InternetGatewayId' --output text | tr '\t' '\n')
            
            echo "Waiting until resources are cleaned..."
            for i in {1..10}; do
              aws ec2 describe-vpcs --vpc-ids $VPC_ID --region ${{ env.AWS_REGION }} >/dev/null 2>&1 || break
              echo "VPC still exists, waiting..."
              sleep 30
            done
            
            aws ec2 delete-vpc --vpc-id $VPC_ID --region ${{ env.AWS_REGION }} || {
              echo "Manual VPC delete failed, removing from Terraform state"
              terraform state rm module.vpc.module.vpc.aws_vpc.this[0] || true
            }
          fi
          
          echo "Retrying terraform destroy..."
          terraform destroy -auto-approve || echo "Destroy failed, manual cleanup may be required"
        }
      working-directory: terraform/eks/minimal

    - name: Cleanup Backend Resources
      if: github.event.inputs.cleanup_backend == 'yes'
      run: |
        echo "Cleaning up backend resources..."
        aws s3 rm s3://${{ env.TF_STATE_BUCKET }} --recursive || true
        aws s3 rb s3://${{ env.TF_STATE_BUCKET }} || true
        aws dynamodb delete-table --table-name ${{ env.TF_STATE_LOCK_TABLE }} --region ${{ env.AWS_REGION }} || true
        echo "Backend cleanup completed"
      working-directory: terraform/eks/minimal
